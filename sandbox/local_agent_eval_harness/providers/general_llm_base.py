# Implement a function `run(prompt: str) -> dict | str` that calls your hosted LLM WITHOUT local file access.
# Return a JSON-compatible Python object (dict/list/scalars). If you return a string, the harness will try to json.loads it.

def run(prompt: str):
    # TODO: Replace this with your actual LLM call.
    # For baseline, we return an empty dict to simulate "I don't know".
    return {}
